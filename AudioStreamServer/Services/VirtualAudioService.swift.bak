//
//  VirtualAudioService.swift
//  AudioStreamServer
//  Created by 0xav10086 on 2025/10/30/00/12.


import Foundation
import AVFoundation
import Combine
import CoreAudio

class AudioCaptureService: NSObject, ObservableObject {
    // MARK: - 发布属性
    @Published var audioLevel: Double = 0.0
    @Published var isCapturing: Bool = false
    @Published var errorMessage: String?
    @Published var audioFormat: String = "未配置"
    @Published var bufferStatus: String = "空闲"
    
    // MARK: - 音频配置
    private let targetDeviceNames = ["BlackHole 2ch", "BlackHole"]
    private let bufferSize: AVAudioFrameCount = 1024
    private var audioFormatDesc: AVAudioFormat?
    
    // MARK: - 音频引擎组件
    private var audioEngine: AVAudioEngine?
    
    // MARK: - 音频数据处理
    private var audioBufferSubject = PassthroughSubject<Data, Never>()
    var audioDataPublisher: AnyPublisher<Data, Never> {
        audioBufferSubject.eraseToAnyPublisher()
    }
    
    // MARK: - 统计信息
    private var totalFramesCaptured: Int64 = 0
    private var lastProcessTime: Date?
    private var bufferQueue: [Data] = []
    private let maxBufferQueueSize = 10
    
    // MARK: - 音频格式属性
    var sampleRate: Double {
        return audioFormatDesc?.sampleRate ?? 0.0
    }
    
    var channelCount: UInt32 {
        return audioFormatDesc?.channelCount ?? 0
    }
    
    // MARK: - 生命周期
    override init() {
        super.init()
        setupAudioSession()
        // 延迟执行设备扫描，避免初始化时的问题
        DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {
            self.listAllAudioDevices()
        }
    }
    
    deinit {
        stopCapture()
    }
    
    // MARK: - 公共方法
    func startCapture() throws {
        guard !isCapturing else { return }
        
        do {
            print("🎧 开始音频捕获...")
            
            // 重置状态
            resetCaptureState()
            
            // 创建并配置音频引擎
            try setupAudioEngine()
            
            // 启动音频引擎
            try audioEngine?.start()
            
            isCapturing = true
            errorMessage = nil
            bufferStatus = "运行中"
            
            print("✅ 音频捕获已启动 - 格式: \(self.audioFormat)")
            
        } catch {
            let errorMsg = "❌ 启动音频捕获失败: \(error.localizedDescription)"
            errorMessage = errorMsg
            bufferStatus = "错误"
            print(errorMsg)
            throw error
        }
    }
    
    func stopCapture() {
        guard isCapturing else { return }
        
        print("🛑 停止音频捕获...")
        
        audioEngine?.stop()
        audioEngine?.inputNode.removeTap(onBus: 0)
        audioEngine = nil
        
        isCapturing = false
        audioLevel = 0.0
        bufferStatus = "已停止"
        bufferQueue.removeAll()
        
        print("✅ 音频捕获已停止")
    }
    
    // MARK: - 音频会话配置
    private func setupAudioSession() {
        print("✅ macOS 音频会话配置完成")
    }
    
    // MARK: - 音频引擎配置
    private func setupAudioEngine() throws {
        audioEngine = AVAudioEngine()
        
        guard let audioEngine = audioEngine else {
            throw NSError(domain: "AudioCaptureService", code: 1,
                          userInfo: [NSLocalizedDescriptionKey: "无法创建音频引擎"])
        }
        
        let inputNode = audioEngine.inputNode
        
        // 配置输入设备
        try configureInputDevice(inputNode: inputNode)
        
        // 获取输入格式
        let inputFormat = inputNode.outputFormat(forBus: 0)
        guard inputFormat.sampleRate > 0 else {
            throw NSError(domain: "AudioCaptureService", code: 2,
                          userInfo: [NSLocalizedDescriptionKey: "输入节点格式无效"])
        }
        
        audioFormatDesc = inputFormat
        updateAudioFormatDisplay()
        
        print("🎛️ 音频输入格式: \(inputFormat.description)")
        
        // 安装音频捕获tap
        installAudioTap(inputNode: inputNode, format: inputFormat)
        
        // 连接节点（虽然我们不需要输出，但保持引擎运行）
        audioEngine.connect(inputNode, to: audioEngine.mainMixerNode, format: inputFormat)
        
        // 准备音频引擎
        audioEngine.prepare()
    }
    
    private func configureInputDevice(inputNode: AVAudioInputNode) throws {
        // 尝试查找 BlackHole 设备
        var targetUID: String?
        
        for deviceName in targetDeviceNames {
            if let uid = findTargetDeviceUID(named: deviceName) {
                targetUID = uid
                print("✅ 找到目标设备: \(deviceName) (UID: \(uid))")
                break
            }
        }
        
        if let targetUID = targetUID {
            // 在 macOS 中，我们通过设置默认输入设备来实现
            setDefaultInputDevice(to: targetUID)
            print("✅ 成功设置输入设备")
        } else {
            print("⚠️ 未找到 BlackHole 设备，使用系统默认输入")
            print("💡 请确保：")
            print("   1. BlackHole 已正确安装")
            print("   2. 在系统设置中将 BlackHole 设为输出设备")
            print("   3. 重启应用或电脑")
        }
    }
    
    private func setDefaultInputDevice(to deviceUID: String) {
        let deviceID = getDeviceID(from: deviceUID)
        guard deviceID != kAudioObjectUnknown else {
            print("❌ 无法获取设备ID")
            return
        }
        
        var propertyAddress = AudioObjectPropertyAddress(
            mSelector: kAudioHardwarePropertyDefaultInputDevice,
            mScope: kAudioObjectPropertyScopeGlobal,
            mElement: kAudioObjectPropertyElementMain
        )
        
        var targetDeviceID = deviceID
        let status = AudioObjectSetPropertyData(
            AudioObjectID(kAudioObjectSystemObject),
            &propertyAddress,
            0,
            nil,
            UInt32(MemoryLayout<AudioDeviceID>.size),
            &targetDeviceID
        )
        
        if status == noErr {
            print("✅ 默认输入设备已设置")
        } else {
            print("⚠️ 设置默认输入设备失败，状态码: \(status)")
        }
    }
    
    private func installAudioTap(inputNode: AVAudioInputNode, format: AVAudioFormat) {
        inputNode.installTap(onBus: 0, bufferSize: bufferSize, format: format) { [weak self] (buffer, time) in
            self?.processAudioBuffer(buffer, time: time)
        }
    }
    
    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer, time: AVAudioTime) {
        guard isCapturing else { return }
        
        // 更新处理时间
        lastProcessTime = Date()
        
        // 计算音频电平
        calculateAudioLevel(from: buffer)
        
        // 转换并发送音频数据
        if let audioData = convertToAudioData(buffer: buffer) {
            totalFramesCaptured += Int64(buffer.frameLength)
            audioBufferSubject.send(audioData)
            
            // 管理缓冲区队列
            manageBufferQueue(audioData)
        }
    }
    
    private func calculateAudioLevel(from buffer: AVAudioPCMBuffer) {
        guard let channelData = buffer.floatChannelData?[0] else { return }
        
        let frameLength = Int(buffer.frameLength)
        var sum: Float = 0.0
        
        for i in 0..<frameLength {
            let sample = channelData[i]
            sum += sample * sample
        }
        
        let rms = sqrt(sum / Float(frameLength))
        let db = 20.0 * log10(rms + 1e-10)
        let normalizedLevel = max(0.0, min(1.0, (db + 60.0) / 60.0))
        
        DispatchQueue.main.async {
            self.audioLevel = Double(normalizedLevel)
        }
    }
    
    private func convertToAudioData(buffer: AVAudioPCMBuffer) -> Data? {
        guard let channelData = buffer.floatChannelData?[0] else { return nil }
        
        let frameLength = Int(buffer.frameLength)
        let dataSize = frameLength * MemoryLayout<Float>.size
        
        return channelData.withMemoryRebound(to: UInt8.self, capacity: dataSize) { pointer in
            return Data(bytes: pointer, count: dataSize)
        }
    }
    
    private func manageBufferQueue(_ audioData: Data) {
        bufferQueue.append(audioData)
        
        // 限制队列大小
        if bufferQueue.count > maxBufferQueueSize {
            bufferQueue.removeFirst()
        }
        
        // 更新缓冲区状态
        updateBufferStatus()
    }
    
    private func updateBufferStatus() {
        let status: String
        if bufferQueue.count == 0 {
            status = "空闲"
        } else if bufferQueue.count < maxBufferQueueSize / 2 {
            status = "正常"
        } else {
            status = "繁忙(\(bufferQueue.count)/\(maxBufferQueueSize))"
        }
        
        DispatchQueue.main.async {
            self.bufferStatus = status
        }
    }
    
    private func updateAudioFormatDisplay() {
        guard let format = audioFormatDesc else {
            audioFormat = "未配置"
            return
        }
        
        audioFormat = "\(Int(format.sampleRate))Hz • \(format.channelCount)声道 • 32-bit Float"
    }
    
    private func resetCaptureState() {
        totalFramesCaptured = 0
        lastProcessTime = nil
        bufferQueue.removeAll()
        audioLevel = 0.0
    }
    
    // MARK: - Core Audio 辅助函数（安全版本）
    private func getDeviceID(from deviceUID: String) -> AudioDeviceID {
        let devices = getAllAudioDevices()
        for device in devices {
            if device.uid == deviceUID {
                return device.id
            }
        }
        
        print("❌ 未找到设备UID: \(deviceUID)")
        return kAudioObjectUnknown
    }

    private func isInputDevice(_ deviceID: AudioDeviceID) -> Bool {
        var propertyAddress = AudioObjectPropertyAddress(
            mSelector: kAudioDevicePropertyStreams,
            mScope: kAudioDevicePropertyScopeInput,
            mElement: kAudioObjectPropertyElementMain
        )
        
        var dataSize: UInt32 = 0
        let status = AudioObjectGetPropertyDataSize(
            deviceID,
            &propertyAddress,
            0,
            nil,
            &dataSize
        )
        
        return status == noErr && dataSize > 0
    }

    private func isOutputDevice(_ deviceID: AudioDeviceID) -> Bool {
        var propertyAddress = AudioObjectPropertyAddress(
            mSelector: kAudioDevicePropertyStreams,
            mScope: kAudioDevicePropertyScopeOutput,
            mElement: kAudioObjectPropertyElementMain
        )
        
        var dataSize: UInt32 = 0
        let status = AudioObjectGetPropertyDataSize(
            deviceID,
            &propertyAddress,
            0,
            nil,
            &dataSize
        )
        
        return status == noErr && dataSize > 0
    }

    // MARK: - 设备信息获取辅助函数（使用安全的 CChar 缓冲区）
    private func getDeviceName(_ deviceID: AudioDeviceID) -> String? {
        var propertyAddress = AudioObjectPropertyAddress(
            mSelector: kAudioObjectPropertyName,
            mScope: kAudioObjectPropertyScopeGlobal,
            mElement: kAudioObjectPropertyElementMain
        )
        
        // 先获取属性数据大小
        var dataSize: UInt32 = 0
        var status = AudioObjectGetPropertyDataSize(
            deviceID,
            &propertyAddress,
            0,
            nil,
            &dataSize
        )
        
        guard status == noErr, dataSize > 0 else {
            print("❌ 无法获取设备名称属性大小: \(status)")
            return nil
        }
        
        // 分配适当大小的 CChar 缓冲区
        var buffer = [CChar](repeating: 0, count: Int(dataSize) + 1)
        
        status = buffer.withUnsafeMutableBytes { bufferPointer in
            guard let baseAddress = bufferPointer.baseAddress else {
                return OSStatus(-1)
            }
            return AudioObjectGetPropertyData(
                deviceID,
                &propertyAddress,
                0,
                nil,
                &dataSize,
                baseAddress
            )
        }
        
        guard status == noErr else {
            print("❌ 获取设备名称失败: \(status)")
            return nil
        }
        
        // 安全地将 C 字符串转换为 Swift 字符串
        return String(cString: buffer)
    }

    private func getDeviceUID(_ deviceID: AudioDeviceID) -> String? {
        var propertyAddress = AudioObjectPropertyAddress(
            mSelector: kAudioDevicePropertyDeviceUID,
            mScope: kAudioObjectPropertyScopeGlobal,
            mElement: kAudioObjectPropertyElementMain
        )
        
        // 先获取属性数据大小
        var dataSize: UInt32 = 0
        var status = AudioObjectGetPropertyDataSize(
            deviceID,
            &propertyAddress,
            0,
            nil,
            &dataSize
        )
        
        guard status == noErr, dataSize > 0 else {
            print("❌ 无法获取设备UID属性大小: \(status)")
            return nil
        }
        
        // 分配适当大小的 CChar 缓冲区
        var buffer = [CChar](repeating: 0, count: Int(dataSize) + 1)
        
        status = buffer.withUnsafeMutableBytes { bufferPointer in
            guard let baseAddress = bufferPointer.baseAddress else {
                return OSStatus(-1)
            }
            return AudioObjectGetPropertyData(
                deviceID,
                &propertyAddress,
                0,
                nil,
                &dataSize,
                baseAddress
            )
        }
        
        guard status == noErr else {
            print("❌ 获取设备UID失败: \(status)")
            return nil
        }
        
        // 安全地将 C 字符串转换为 Swift 字符串
        return String(cString: buffer)
    }
    
    private func getAllAudioDevices() -> [(id: AudioDeviceID, name: String, uid: String)] {
        var devices: [(AudioDeviceID, String, String)] = []
        
        var propertyAddress = AudioObjectPropertyAddress(
            mSelector: kAudioHardwarePropertyDevices,
            mScope: kAudioObjectPropertyScopeGlobal,
            mElement: kAudioObjectPropertyElementMain
        )
        
        var dataSize: UInt32 = 0
        let status = AudioObjectGetPropertyDataSize(
            AudioObjectID(kAudioObjectSystemObject),
            &propertyAddress,
            0,
            nil,
            &dataSize
        )
        
        guard status == noErr, dataSize > 0 else {
            print("❌ 无法获取音频设备列表大小: \(status)")
            return devices
        }
        
        let deviceCount = Int(dataSize) / MemoryLayout<AudioDeviceID>.size
        var deviceIDs = [AudioDeviceID](repeating: 0, count: deviceCount)
        
        let getStatus = AudioObjectGetPropertyData(
            AudioObjectID(kAudioObjectSystemObject),
            &propertyAddress,
            0,
            nil,
            &dataSize,
            &deviceIDs
        )
        
        guard getStatus == noErr else {
            print("❌ 获取音频设备列表失败: \(getStatus)")
            return devices
        }
        
        for deviceID in deviceIDs {
            if let name = getDeviceName(deviceID), let uid = getDeviceUID(deviceID) {
                devices.append((deviceID, name, uid))
            }
        }
        
        return devices
    }
        
    // 简化设备查找逻辑
    func findTargetDeviceUID(named name: String) -> String? {
        let devices = getAllAudioDevices()
        
        for device in devices {
            if device.name.lowercased().contains(name.lowercased()) {
                print("✅ 找到匹配设备: \(device.name) -> UID: \(device.uid)")
                return device.uid
            }
        }
        
        print("❌ 未找到设备: \(name)")
        return nil
    }
        
    // MARK: - 设备列表调试
    private func listAllAudioDevices() {
        print("🔍 扫描所有音频设备...")
        let devices = getAllAudioDevices()
        
        print("📋 找到 \(devices.count) 个音频设备:")
        for device in devices {
            let isInput = isInputDevice(device.id)
            let isOutput = isOutputDevice(device.id)
            let type = isInput && isOutput ? "输入/输出" : (isInput ? "输入" : (isOutput ? "输出" : "未知"))
            print("   - \(device.name) [\(device.uid)] - \(type)")
        }
    }
}

// MARK: - Core Audio 常量
private let kAudioObjectSystemObject: AudioObjectID = 1
private let kAudioHardwarePropertyDevices: AudioObjectPropertySelector = 0x64657623 // 'dev#'
private let kAudioDevicePropertyStreams: AudioObjectPropertySelector = 0x73747223 // 'str#'
private let kAudioObjectPropertyName: AudioObjectPropertySelector = 0x6E616D65 // 'name'
private let kAudioDevicePropertyDeviceUID: AudioObjectPropertySelector = 0x75696420 // 'uid '
private let kAudioDevicePropertyScopeInput: AudioObjectPropertyScope = 0x696E7075 // 'inpu'
private let kAudioDevicePropertyScopeOutput: AudioObjectPropertyScope = 0x6F757470 // 'outp'
private let kAudioObjectPropertyScopeGlobal: AudioObjectPropertyScope = 0x676C626C // 'glbl'
private let kAudioObjectPropertyElementMain: AudioObjectPropertyElement = 0
private let kAudioHardwarePropertyDefaultInputDevice: AudioObjectPropertySelector = 0x64696E20 // 'din '
private let kAudioObjectUnknown: AudioDeviceID = 0
